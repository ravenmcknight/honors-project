---
title: "Poisson Regression"
author: "Raven McKnight"
date: "12/3/2019"
output: 
  html_document: 
    toc: true
    toc_float: true
    theme: paper
    code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#install.packages("INLA", repos=c(getOption("repos"), INLA="https://inla.r-inla-download.org/R/stable"), dep=TRUE)
library(INLA)
library(rstan)
library(shinystan)
library(data.table)
library(ggplot2)
library(rgdal)
library(sf)
library(tigris)
library(bayesplot)

options(mc.cores = parallel::detectCores())
options(tigris_class = "sf")
options(tigris_use_cache = TRUE)

mod_dat <- readRDS('/Users/mcknigri/Documents/honors/honors-project/data/modeling-dat/p_dat_scaled.RDS')
setDT(mod_dat)

counties <- c("Anoka", "Carver", "Dakota", "Hennepin", "Ramsey", "Scott", "Washington")
bgs <- block_groups("MN", counties, 2016)
```

# Introduction

Before moving on to spatial models, we can work with a simpler intermediate step: Bayesian Poisson regression. We expect Poisson regression to be "better" than a simple linear regression for several reasons. First, ridership is a count variable so using a Poisson is more ture to the distribution of our response.

Second, it allows us to use an offset term. Offset terms are covariates with their parameters set to 1. They are used to scale the mean of a Poisson variable, like a rate. In disease mapping studies, the offset is often set to the total population of areal unit $i$, which is a natural maximum to disease counts. In our case, there is no obvious bounding maximum, but total population and total times a bus makes a stop in block group $i$ are natural places to start. 

# The Simplest Model

Let $Y_i$ equal the average number of weekday boardings in block group $i$ in 2017, and let $E_i$ equal the average number of times a bus stops in that block group. Then the Poisson regression can be written

\begin{align}
Y_i & \sim \text{Poisson}(E_i\lambda_i) \\
\eta_i = log(\lambda_i) &= \mu + \sum_{n=1}^{4}x_n\beta\\
\theta & \sim N(0, 1)
\end{align}

where $\lambda_i$ is the relative "risk" of ridership given exposure to covariates $x\beta$. 

We'll use the same four covariates as we used in the linear regression: population density, employment density, percent of households with no vehicle, and a walkability metric. 

# Results

```{r}
mod_dat <- mod_dat[!is.na(daily_boards_per_stop) & !is.na(pop_density) & !is.na(emp_density) & !is.na(perc_no_veh) & !is.na(walkability) & !is.na(daily_stops)]

xdat <- mod_dat[, -c("GEOID", "daily_boards_per_stop", "sqkm", "perc_transit_comm")] # still need to fix that var
xdat <- na.omit(xdat)

y <- xdat$daily_boards
E <- xdat$daily_stops

N <- nrow(xdat)

K <- 27
x <- as.matrix(xdat)

standat1 <- list(y = y, E = E, x = x, K = K, N = N)

poisson <- "/Users/raven/Documents/honors/honors-project/stan/poisson.stan"

#poisson_fitsimp <- stan(poisson, data = standat1, warmup = 1000, iter = 2000)
#saveRDS(poisson_fitsimp, "/Users/raven/Documents/honors/honors-project/fits/poisson_fitsimp.RDS")

poisson_fitsimp <- readRDS("/Users/raven/Documents/honors/honors-project/fits/poisson_fitsimp.RDS")


print(poisson_fitsimp, pars = c("mu", "betas[1]", "betas[2]", "betas[3]", "betas[4]"), probs=c(0.025, 0.5, 0.975))
#launch_shinystan(poisson_fitsimp)
```



## Predictions
```{r}
posterior <- rstan::extract(poisson_fitsimp)
yrep <- matrix(ncol = 1513, nrow = 100)

for(i in 1:100){
  yrep[i, ] <- rpois(1513, posterior$lambda*E)
}

pp_check(y, yrep, ppc_dens_overlay) + 
  theme_minimal() +
  xlim(0, 200) +
  labs(title = "Actual versus fitted") + xlim(0, 100)
```


```{r}
mod_dat[, predicted_boards := rpois(lambda = daily_stops * exp(-1.13 + 0.06*pop_density + 0.04*emp_density + 0.16*perc_no_veh), n = nrow(mod_dat))]

mod_dat_sf <- dplyr::left_join(bgs, mod_dat)

ggplot(mod_dat_sf, aes(x=daily_boards, y = predicted_boards)) +
  geom_point() +
  theme_minimal() +
  labs(title = "Actual versus predicted", subtitle = "Clearly overstimating outliers") 

ggplot(mod_dat_sf %>% dplyr::filter(daily_boards < 500), aes(x=daily_boards, y = predicted_boards)) +
  geom_point() +
  theme_minimal() +
  labs(title = "Actual versus predicted", subtitle = "Clearly overstimating outliers") +
  xlim(0, 500) + ylim(0, 500)
```

```{r}
a <- ggplot(mod_dat_sf %>% dplyr::filter(!is.na(daily_boards) & daily_boards != 0), aes(fill=log(daily_boards))) + 
  geom_sf(lwd = 0) +
  scale_fill_viridis_c() + 
  theme_minimal() +
  labs(title = "Observed log daily boardings") +
  theme(legend.position = 'none')

b <- ggplot(mod_dat_sf %>% dplyr::filter(!is.na(daily_boards)), aes(fill=log(predicted_boards))) + 
  geom_sf(lwd = 0) +
  scale_fill_viridis_c() + 
  theme_minimal() +
  labs(title = "Predicted log daily boardings") +
  theme(legend.position = 'none')

gridExtra::grid.arrange(a, b, ncol = 2)
```

It looks like the simple Poisson regression is beginning to capture the correct spatial pattern, though it's underestimating some areas on the suburbs. 

## Residuals

```{r}
ggplot(mod_dat_sf %>% dplyr::filter(!is.na(daily_boards)), aes(fill=log(daily_boards) - log(predicted_boards))) + 
  geom_sf(lwd = 0) +
  scale_fill_viridis_c() + 
  theme_minimal() +
  labs(title = "Residuals") +
  theme(legend.position = 'none')
```

In general, it seems the model is failing in a few ways: overestimating ridership in high-ridership block groups, and underestimating the number of block groups with low ridership. 

Let's see if these residuals are spatially autocorrelated:

```{r}
library(spdep)

resid_dat <- mod_dat_sf %>% 
  dplyr::filter(!is.na(daily_boards))

nb <- poly2nb(resid_dat)
W <- nb2mat(nb, style = "B", zero.policy = TRUE)
listW <- nb2listw(nb, zero.policy = TRUE)

resid_dat <- resid_dat %>%
  dplyr::mutate(resid = daily_boards - predicted_boards)

moran.mc(resid_dat$resid, listW, nsim = 9999, zero.policy = TRUE)
```


According to the Moran simulation, they're not spatially clustered, but we still haven't found a good way to measure "linear" clustering. 


# An Improvement

One way we could improve this model is by explicitly modeling the extra-Poisson variance (or overdispersion) which may be contributing the the poor fit above. We can add a $\theta$ parameter (scaled by $\sigma$, following the bym2 model) to address this variation as follows

\begin{align}
Y_i & \sim \text{Poisson}(E_i\lambda_i) \\
\eta_i = log(\lambda_i) &= \mu + \sum_{n=1}^{4}x_n\beta + \theta*\sigma \\
\theta & \sim N(0, 1)
\end{align}

## Results

```{r}
poisson_theta <- "/Users/mcknigri/Documents/honors/honors-project/stan/poisson_theta.stan"

poisson_theta_fit_LASSO <- stan(poisson_theta, data = standat1, warmup = 7000, iter = 8000)
#saveRDS(poisson_theta_fit, "/Users/raven/Documents/honors/honors-project/fits/poisson_theta_test.RDS")

poisson_theta_fit <- readRDS("/Users/raven/Documents/honors/honors-project/fits/poisson_theta_test.RDS")

print(poisson_theta_fit, pars = c("mu", "betas[1]", "betas[2]", "betas[3]", "betas[4]", "theta[5]", "eta[5]", "lambda[5]"), probs=c(0.025, 0.5, 0.975))

launch_shinystan(poisson_theta_fit_LASSO)
```

This also has a lot of autocorrelation in the chains, needs to be run for more iterations.  

```{r}
posterior2 <- rstan::extract(poisson_theta_fit)
yrep2 <- matrix(ncol = 1513, nrow = 100)

for(i in 1:100){
  yrep2[i, ] <- rpois(1513, posterior2$lambda[i,]*E)
}

pp_check(y, yrep2, ppc_dens_overlay) + 
  theme_minimal() +
  xlim(0, 200) +
  labs(title = "Actual versus fitted") + xlim(0, 100)
```

The next improvement would be to determine roughly how much of the variation currently modeled by $\theta * \sigma$ is due to unmeasured covariates vs pure overdispersion vs spatial variance. 


```{r}
pairs(poisson_horseshoe_fit)
```

